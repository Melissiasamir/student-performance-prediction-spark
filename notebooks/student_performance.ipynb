{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa965596",
   "metadata": {
    "id": "fa965596"
   },
   "source": [
    "# Student Performance Prediction (Classification)\n",
    "\n",
    "**Dataset:** `StudentsPerformance.csv`  \n",
    "**Source:** [Kaggle - Students Performance in Exams](https://www.kaggle.com/datasets/spscientist/students-performance-in-exams)  \n",
    "\n",
    "## Project Idea\n",
    "\n",
    "This project predicts student academic performance based on demographic and socioeconomic features using Apache Spark for scalable machine learning.\n",
    "\n",
    "#### The data contains:\n",
    "\n",
    "**Demographic features:** gender, race/ethnicity\n",
    "\n",
    "**Socioeconomic features:** parental level of education, lunch type\n",
    "\n",
    "**Academic preparation:** test preparation course\n",
    "\n",
    "**Target scores:** math score, reading score, writing score\n",
    "\n",
    "## Goal\n",
    "\n",
    "Predict whether a student will have High, Medium, or Low performance based on their average test score.\n",
    "\n",
    "Help educators identify students who may need additional support.\n",
    "\n",
    "Use Spark ML for scalability and efficient handling of large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b2354",
   "metadata": {},
   "source": [
    "## Phase 0: Import libraries & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2516dfb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2516dfb6",
    "outputId": "072dc3cf-626e-4ce2-b574-bf6c1f4ee855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Created Successfully\n"
     ]
    }
   ],
   "source": [
    "#  Create Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Student Performance - Data Understanding\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Session Created Successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900ceb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n",
      "Shape: 1000 rows, 8 columns\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\n",
    "    \"../data/raw/StudentsPerformance.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(\"Dataset loaded\")\n",
    "print(f\"Shape: {df.count()} rows, {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442eb6f",
   "metadata": {
    "id": "3442eb6f"
   },
   "source": [
    "## Phase 1: Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ef3197",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1ef3197",
    "outputId": "2c86d3b9-fcbe-48f4-fb39-13bd9546a764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: 1000 rows, 8 columns\n"
     ]
    }
   ],
   "source": [
    "# Dataset Shape\n",
    "rows = df.count()\n",
    "cols = len(df.columns)\n",
    "\n",
    "print(f\"Dataset Shape: {rows} rows, {cols} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afdc256",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8afdc256",
    "outputId": "500e2abb-ccdb-4659-8d76-dde52b1d9579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|lunch       |test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|female|group B       |bachelor's degree          |standard    |none                   |72        |72           |74           |\n",
      "|female|group C       |some college               |standard    |completed              |69        |90           |88           |\n",
      "|female|group B       |master's degree            |standard    |none                   |90        |95           |93           |\n",
      "|male  |group A       |associate's degree         |free/reduced|none                   |47        |57           |44           |\n",
      "|male  |group C       |some college               |standard    |none                   |76        |78           |75           |\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Random sample:\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|lunch       |test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|female|group E       |some college               |standard    |none                   |62        |73           |70           |\n",
      "|female|group C       |associate's degree         |free/reduced|completed              |68        |67           |69           |\n",
      "|male  |group A       |high school                |free/reduced|none                   |48        |45           |41           |\n",
      "|female|group D       |some college               |standard    |none                   |98        |100          |99           |\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview Dataset\n",
    "print(\"First 5 rows:\")\n",
    "df.show(5, truncate=False)\n",
    "\n",
    "print(\"\\nRandom sample:\")\n",
    "df.sample(fraction=0.01, seed=42).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73946478",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73946478",
    "outputId": "073e5b80-2a1a-4fc5-db49-33b2b50f90bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Schema:\n",
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: integer (nullable = true)\n",
      " |-- reading score: integer (nullable = true)\n",
      " |-- writing score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset Schema & Info\n",
    "print(\"Dataset Schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be487141",
   "metadata": {
    "id": "be487141"
   },
   "source": [
    "#### Identify Columns Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f43cab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47f43cab",
    "outputId": "bc794b5e-6a91-4c15-88ba-eaadb5d45c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: ['math score', 'reading score', 'writing score']\n",
      "Categorical Columns: ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical & categorical columns\n",
    "numerical_cols = ['math score', 'reading score', 'writing score']\n",
    "categorical_cols = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "\n",
    "print(\"Numerical Columns:\", numerical_cols)\n",
    "print(\"Categorical Columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fcc612a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fcc612a",
    "outputId": "3bb12eb2-8562-49d0-c692-4cbee8f967bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values per column:\n",
      "gender: 2\n",
      "race/ethnicity: 5\n",
      "parental level of education: 6\n",
      "lunch: 2\n",
      "test preparation course: 2\n",
      "math score: 81\n",
      "reading score: 72\n",
      "writing score: 77\n"
     ]
    }
   ],
   "source": [
    "# Unique Values per Column\n",
    "print(\"Unique values per column:\")\n",
    "for col_name in df.columns:\n",
    "    print(f\"{col_name}: {df.select(col_name).distinct().count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec7e9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score statistics:\n",
      "+--------+--------+--------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "|Min Math|Max Math|Avg Math|Min Reading|Max Reading|Avg Reading|Min Writing|Max Writing|Avg Writing|\n",
      "+--------+--------+--------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "|       0|     100|  66.089|         17|        100|     69.169|         10|        100|     68.054|\n",
      "+--------+--------+--------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score statistics\n",
    "print(\"Score statistics:\")\n",
    "df.select(\n",
    "    F.min(\"math score\").alias(\"Min Math\"),\n",
    "    F.max(\"math score\").alias(\"Max Math\"),\n",
    "    F.avg(\"math score\").alias(\"Avg Math\"),\n",
    "    F.min(\"reading score\").alias(\"Min Reading\"),\n",
    "    F.max(\"reading score\").alias(\"Max Reading\"),\n",
    "    F.avg(\"reading score\").alias(\"Avg Reading\"),\n",
    "    F.min(\"writing score\").alias(\"Min Writing\"),\n",
    "    F.max(\"writing score\").alias(\"Max Writing\"),\n",
    "    F.avg(\"writing score\").alias(\"Avg Writing\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea1bf5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math score distribution (binned):\n",
      "+--------+-----+\n",
      "|math_bin|count|\n",
      "+--------+-----+\n",
      "|   60-69|  268|\n",
      "|   70-79|  216|\n",
      "|   80-89|  135|\n",
      "|  90-100|   58|\n",
      "|Below 60|  323|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score distributions\n",
    "print(\"Math score distribution (binned):\")\n",
    "df.withColumn(\"math_bin\", \n",
    "    F.when(F.col(\"math score\") >= 90, \"90-100\")\n",
    "     .when(F.col(\"math score\") >= 80, \"80-89\")\n",
    "     .when(F.col(\"math score\") >= 70, \"70-79\")\n",
    "     .when(F.col(\"math score\") >= 60, \"60-69\")\n",
    "     .otherwise(\"Below 60\")\n",
    ").groupBy(\"math_bin\").count().orderBy(\"math_bin\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6c2c000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range check for score features:\n",
      "math score: min=0, max=100\n",
      "reading score: min=17, max=100\n",
      "writing score: min=10, max=100\n"
     ]
    }
   ],
   "source": [
    "# Range Validation for Score Features\n",
    "print(\"Range check for score features:\")\n",
    "for score_col in numerical_cols:\n",
    "    min_val = df.agg(F.min(score_col)).collect()[0][0]\n",
    "    max_val = df.agg(F.max(score_col)).collect()[0][0]\n",
    "    print(f\"{score_col}: min={min_val}, max={max_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b071ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column value counts:\n",
      "gender: 2 unique values\n",
      "race/ethnicity: 5 unique values\n",
      "parental level of education: 6 unique values\n",
      "lunch: 2 unique values\n",
      "test preparation course: 2 unique values\n",
      "math score: 81 unique values\n",
      "reading score: 72 unique values\n",
      "writing score: 77 unique values\n"
     ]
    }
   ],
   "source": [
    "# No high-cardinality identifiers in this dataset\n",
    "# All columns are meaningful features\n",
    "print(\"Column value counts:\")\n",
    "for col_name in df.columns:\n",
    "    unique_count = df.select(col_name).distinct().count()\n",
    "    print(f\"{col_name}: {unique_count} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58fff4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of gender:\n",
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|female|  518|\n",
      "|  male|  482|\n",
      "+------+-----+\n",
      "\n",
      "\n",
      "Distribution of race/ethnicity:\n",
      "+--------------+-----+\n",
      "|race/ethnicity|count|\n",
      "+--------------+-----+\n",
      "|       group C|  319|\n",
      "|       group D|  262|\n",
      "|       group B|  190|\n",
      "|       group E|  140|\n",
      "|       group A|   89|\n",
      "+--------------+-----+\n",
      "\n",
      "\n",
      "Distribution of parental level of education:\n",
      "+---------------------------+-----+\n",
      "|parental level of education|count|\n",
      "+---------------------------+-----+\n",
      "|               some college|  226|\n",
      "|         associate's degree|  222|\n",
      "|                high school|  196|\n",
      "|           some high school|  179|\n",
      "|          bachelor's degree|  118|\n",
      "|            master's degree|   59|\n",
      "+---------------------------+-----+\n",
      "\n",
      "\n",
      "Distribution of lunch:\n",
      "+------------+-----+\n",
      "|       lunch|count|\n",
      "+------------+-----+\n",
      "|    standard|  645|\n",
      "|free/reduced|  355|\n",
      "+------------+-----+\n",
      "\n",
      "\n",
      "Distribution of test preparation course:\n",
      "+-----------------------+-----+\n",
      "|test preparation course|count|\n",
      "+-----------------------+-----+\n",
      "|                   none|  642|\n",
      "|              completed|  358|\n",
      "+-----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Categorical Feature Distributions\n",
    "for col_name in categorical_cols:\n",
    "    print(f\"\\nDistribution of {col_name}:\")\n",
    "    df.groupBy(col_name).count().orderBy(F.desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cd296",
   "metadata": {},
   "source": [
    "## Phase 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e28a1",
   "metadata": {
    "id": "b85e28a1"
   },
   "source": [
    "### Handle Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db34e9fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db34e9fd",
    "outputId": "714c5c45-a831-4509-e802-fe15c53f7045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+\n",
      "|     0|             0|                          0|    0|                      0|         0|            0|            0|\n",
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+\n",
      "\n",
      "\n",
      "Missing values handled (dataset has no nulls)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values first\n",
    "print(\"Missing values per column:\")\n",
    "df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "\n",
    "# Numerical columns -> fill with median (if any nulls)\n",
    "for col_name in numerical_cols:\n",
    "    null_count = df.filter(F.col(col_name).isNull()).count()\n",
    "    if null_count > 0:\n",
    "        median_value = df.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "        df = df.fillna({col_name: median_value})\n",
    "        print(f\"Filled {null_count} nulls in {col_name} with median {median_value}\")\n",
    "\n",
    "# Categorical columns -> fill with mode (if any nulls)\n",
    "for col_name in categorical_cols:\n",
    "    null_count = df.filter(F.col(col_name).isNull()).count()\n",
    "    if null_count > 0:\n",
    "        mode_row = df.groupBy(col_name).count().orderBy(F.desc(\"count\")).first()\n",
    "        if mode_row is not None and mode_row[0] is not None:\n",
    "            mode_value = str(mode_row[0])\n",
    "            df = df.fillna({col_name: mode_value})\n",
    "            print(f\"Filled {null_count} nulls in {col_name} with mode '{mode_value}'\")\n",
    "\n",
    "print(\"\\nMissing values handled (dataset has no nulls)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b679b22f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b679b22f",
    "outputId": "c42bd9d4-3548-4d57-aaa7-a91ce0007e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of duplicate rows: 0\n",
      "✅ Duplicate rows removed\n",
      " New Dataset Shape: 1000 rows\n"
     ]
    }
   ],
   "source": [
    "# Check Duplicates\n",
    "duplicates_count = df.count() - df.dropDuplicates().count()\n",
    "print(f\" Number of duplicate rows: {duplicates_count}\")\n",
    "\n",
    "# Remove Duplicates\n",
    "df = df.dropDuplicates()\n",
    "print(\"✅ Duplicate rows removed\")\n",
    "print(\" New Dataset Shape:\", df.count(), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9559ad08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9559ad08",
    "outputId": "b4474fa3-46c9-4c42-947f-7f846ce9069f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score range verification:\n",
      "math score: Valid range [0, 100]\n",
      "reading score: Valid range [17, 100]\n",
      "writing score: Valid range [10, 100]\n",
      "\n",
      "No outlier capping needed - scores are within valid 0-100 range\n"
     ]
    }
   ],
   "source": [
    "# For score columns (0-100 range), we don't apply IQR capping\n",
    "# as all values are valid test scores within the expected range\n",
    "# Just verify the ranges are correct\n",
    "\n",
    "print(\"Score range verification:\")\n",
    "for col_name in numerical_cols:\n",
    "    min_val = df.agg(F.min(col_name)).collect()[0][0]\n",
    "    max_val = df.agg(F.max(col_name)).collect()[0][0]\n",
    "    if min_val >= 0 and max_val <= 100:\n",
    "        print(f\"{col_name}: Valid range [{min_val}, {max_val}]\")\n",
    "    else:\n",
    "        print(f\"{col_name}: WARNING - outside 0-100 range!\")\n",
    "\n",
    "print(\"\\nNo outlier capping needed - scores are within valid 0-100 range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c3b124",
   "metadata": {},
   "source": [
    "## Phase 3: Feature Engineering (Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c997aa38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c997aa38",
    "outputId": "6472e6c3-fde3-4353-cff0-59edaa0c8248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable (PerformanceLevel) created based on average score\n",
      "\n",
      "Performance Level Distribution:\n",
      "+----------------+-----+\n",
      "|PerformanceLevel|count|\n",
      "+----------------+-----+\n",
      "|            High|  198|\n",
      "|             Low|  285|\n",
      "|          Medium|  517|\n",
      "+----------------+-----+\n",
      "\n",
      "Average score statistics per level:\n",
      "+----------------+----+------------------+------------------+\n",
      "|PerformanceLevel| Min|               Max|              Mean|\n",
      "+----------------+----+------------------+------------------+\n",
      "|            High|80.0|             100.0| 87.06397306397307|\n",
      "|             Low| 9.0|59.666666666666664|50.328654970760226|\n",
      "|          Medium|60.0| 79.66666666666667| 69.99677627337196|\n",
      "+----------------+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create average score from all three test scores\n",
    "df = df.withColumn(\n",
    "    \"average_score\",\n",
    "    (F.col(\"math score\") + F.col(\"reading score\") + F.col(\"writing score\")) / 3\n",
    ")\n",
    "\n",
    "# Create target variable for classification based on average score\n",
    "df = df.withColumn(\n",
    "    \"PerformanceLevel\",\n",
    "    F.when(F.col(\"average_score\") >= 80, \"High\")\n",
    "     .when(F.col(\"average_score\") >= 60, \"Medium\")\n",
    "     .otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "print(\"Target variable (PerformanceLevel) created based on average score\")\n",
    "print(\"\\nPerformance Level Distribution:\")\n",
    "df.groupBy(\"PerformanceLevel\").count().orderBy(\"PerformanceLevel\").show()\n",
    "\n",
    "print(\"Average score statistics per level:\")\n",
    "df.groupBy(\"PerformanceLevel\").agg(\n",
    "    F.min(\"average_score\").alias(\"Min\"),\n",
    "    F.max(\"average_score\").alias(\"Max\"),\n",
    "    F.avg(\"average_score\").alias(\"Mean\")\n",
    ").orderBy(\"PerformanceLevel\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5f9f5a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5f9f5a8",
    "outputId": "96020d8a-351b-4c58-e801-5ae43f6a28ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML-ready dataset prepared: 1000 rows, 10 columns\n",
      "\n",
      "Final columns:\n",
      "  - gender\n",
      "  - race/ethnicity\n",
      "  - parental level of education\n",
      "  - lunch\n",
      "  - test preparation course\n",
      "  - math score\n",
      "  - reading score\n",
      "  - writing score\n",
      "  - average_score\n",
      "  - PerformanceLevel\n"
     ]
    }
   ],
   "source": [
    "# Prepare ML-ready dataset\n",
    "# Keep all features - no identifiers to drop in this dataset\n",
    "df_ml = df\n",
    "\n",
    "print(f\"ML-ready dataset prepared: {df_ml.count()} rows, {len(df_ml.columns)} columns\")\n",
    "print(\"\\nFinal columns:\")\n",
    "for col_name in df_ml.columns:\n",
    "    print(f\"  - {col_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed01311",
   "metadata": {},
   "source": [
    "### Validate Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e07877e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values check:\n",
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+-------------+----------------+\n",
      "|gender|race/ethnicity|parental level of education|lunch|test preparation course|math score|reading score|writing score|average_score|PerformanceLevel|\n",
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+-------------+----------------+\n",
      "|     0|             0|                          0|    0|                      0|         0|            0|            0|            0|               0|\n",
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+-------------+----------------+\n",
      "\n",
      "Score ranges:\n",
      "  math score: [0, 100]\n",
      "  reading score: [17, 100]\n",
      "  writing score: [10, 100]\n",
      "\n",
      "Cleaned ML-ready Dataset Shape: 1000 rows, 10 columns\n"
     ]
    }
   ],
   "source": [
    "# Missing values check\n",
    "print(\"Missing values check:\")\n",
    "df_ml.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_ml.columns]).show()\n",
    "\n",
    "# Score range check\n",
    "print(\"Score ranges:\")\n",
    "for col_name in numerical_cols:\n",
    "    min_val = df_ml.agg(F.min(F.col(col_name))).collect()[0][0]\n",
    "    max_val = df_ml.agg(F.max(F.col(col_name))).collect()[0][0]\n",
    "    print(f\"  {col_name}: [{min_val}, {max_val}]\")\n",
    "\n",
    "# Shape check\n",
    "print(f\"\\nCleaned ML-ready Dataset Shape: {df_ml.count()} rows, {len(df_ml.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220254c0",
   "metadata": {
    "id": "220254c0"
   },
   "source": [
    "## Phase 4: Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e132284e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e132284e",
    "outputId": "e75598e5-7e4d-4d74-ce26-4408b8af194d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset saved successfully\n"
     ]
    }
   ],
   "source": [
    "df_ml.toPandas().to_csv(\n",
    "    r\"../data/cleaned/student_performance_cleaned.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"✅ Cleaned dataset saved successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522281d2",
   "metadata": {
    "id": "522281d2"
   },
   "source": [
    "## Phase 5: Statistical Analysis & Data Summaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4085317d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4085317d",
    "outputId": "9b007045-72f9-458f-be5f-3211e163b405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for score columns:\n",
      "+-------+------------------+-----------------+------------------+------------------+\n",
      "|summary|        math score|    reading score|     writing score|     average_score|\n",
      "+-------+------------------+-----------------+------------------+------------------+\n",
      "|  count|              1000|             1000|              1000|              1000|\n",
      "|   mean|            66.089|           69.169|            68.054| 67.77066666666673|\n",
      "| stddev|15.163080096009455|14.60019193725221|15.195657010869656|14.257325984669148|\n",
      "|    min|                 0|               17|                10|               9.0|\n",
      "|    max|               100|              100|               100|             100.0|\n",
      "+-------+------------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select score columns for summary statistics\n",
    "score_cols = numerical_cols + ['average_score']\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary statistics for score columns:\")\n",
    "df.select(score_cols).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e2ee1",
   "metadata": {
    "id": "5a0e2ee1"
   },
   "source": [
    "### Categorical Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b79aff2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b79aff2f",
    "outputId": "df162ded-7ebe-49d6-fa7d-b161c00e5276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of gender:\n",
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|female|  518|\n",
      "|  male|  482|\n",
      "+------+-----+\n",
      "\n",
      "\n",
      "Distribution of race/ethnicity:\n",
      "+--------------+-----+\n",
      "|race/ethnicity|count|\n",
      "+--------------+-----+\n",
      "|       group C|  319|\n",
      "|       group D|  262|\n",
      "|       group B|  190|\n",
      "|       group E|  140|\n",
      "|       group A|   89|\n",
      "+--------------+-----+\n",
      "\n",
      "\n",
      "Distribution of parental level of education:\n",
      "+---------------------------+-----+\n",
      "|parental level of education|count|\n",
      "+---------------------------+-----+\n",
      "|               some college|  226|\n",
      "|         associate's degree|  222|\n",
      "|                high school|  196|\n",
      "|           some high school|  179|\n",
      "|          bachelor's degree|  118|\n",
      "|            master's degree|   59|\n",
      "+---------------------------+-----+\n",
      "\n",
      "\n",
      "Distribution of lunch:\n",
      "+------------+-----+\n",
      "|       lunch|count|\n",
      "+------------+-----+\n",
      "|    standard|  645|\n",
      "|free/reduced|  355|\n",
      "+------------+-----+\n",
      "\n",
      "\n",
      "Distribution of test preparation course:\n",
      "+-----------------------+-----+\n",
      "|test preparation course|count|\n",
      "+-----------------------+-----+\n",
      "|                   none|  642|\n",
      "|              completed|  358|\n",
      "+-----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Frequency counts for categorical features\n",
    "for col_name in categorical_cols:\n",
    "    print(f\"\\nDistribution of {col_name}:\")\n",
    "    df.groupBy(col_name).count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41fbc25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's d effect size (High vs Low performance):\n",
      "  math score: 3.985 (large effect)\n",
      "  reading score: 4.898 (large effect)\n",
      "  writing score: 4.737 (large effect)\n",
      "  average_score: 5.374 (large effect)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cohens_d(group1, group2):\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    pooled_std = np.sqrt((std1**2 + std2**2) / 2)\n",
    "    return (mean1 - mean2) / pooled_std\n",
    "\n",
    "print(\"Cohen's d effect size (High vs Low performance):\")\n",
    "for col_name in score_cols:\n",
    "    high = df.filter(df[\"PerformanceLevel\"] == \"High\").select(col_name).toPandas()[col_name]\n",
    "    low = df.filter(df[\"PerformanceLevel\"] == \"Low\").select(col_name).toPandas()[col_name]\n",
    "    \n",
    "    if len(high) > 1 and len(low) > 1:\n",
    "        d = cohens_d(high, low)\n",
    "        effect = \"large\" if abs(d) > 0.8 else \"medium\" if abs(d) > 0.5 else \"small\"\n",
    "        print(f\"  {col_name}: {d:.3f} ({effect} effect)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d411a",
   "metadata": {
    "id": "527d411a"
   },
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e6a24e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "3e6a24e9",
    "outputId": "04a417af-58f8-47ab-8397-e6501ffc7d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix for score columns:\n",
      "               math score  reading score  writing score  average_score\n",
      "math score           1.00           0.82           0.80           0.92\n",
      "reading score        0.82           1.00           0.95           0.97\n",
      "writing score        0.80           0.95           1.00           0.97\n",
      "average_score        0.92           0.97           0.97           1.00\n"
     ]
    }
   ],
   "source": [
    "# Convert score features to Pandas for correlation analysis\n",
    "corr_matrix = df.select(score_cols).toPandas().corr()\n",
    "\n",
    "print(\"Correlation matrix for score columns:\")\n",
    "print(corr_matrix.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09967c",
   "metadata": {
    "id": "3f09967c"
   },
   "source": [
    "### Multicollinearity Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0d4f086",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0d4f086",
    "outputId": "58094fa7-b764-4663-82da-1d972fef80aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated pairs (|r| > 0.8):\n",
      "  math score <-> reading score: r = 0.82\n",
      "  math score <-> writing score: r = 0.8\n",
      "  math score <-> average_score: r = 0.92\n",
      "  reading score <-> writing score: r = 0.95\n",
      "  reading score <-> average_score: r = 0.97\n",
      "  writing score <-> average_score: r = 0.97\n"
     ]
    }
   ],
   "source": [
    "# Check for high correlations (multicollinearity)\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(score_cols)):\n",
    "    for j in range(i + 1, len(score_cols)):\n",
    "        corr_value = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > 0.8:\n",
    "            high_corr_pairs.append(\n",
    "                (score_cols[i], score_cols[j], round(corr_value, 2))\n",
    "            )\n",
    "\n",
    "print(\"Highly correlated pairs (|r| > 0.8):\")\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\"  {pair[0]} <-> {pair[1]}: r = {pair[2]}\")\n",
    "\n",
    "if not high_corr_pairs:\n",
    "    print(\"  None found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6c5fd",
   "metadata": {},
   "source": [
    "### Features Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc1071a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores by Performance Level:\n",
      "+----------------+-----------------+-----------------+-----------------+------------------+\n",
      "|PerformanceLevel|math score       |reading score    |writing score    |average_score     |\n",
      "+----------------+-----------------+-----------------+-----------------+------------------+\n",
      "|High            |85.13636363636364|88.38383838383838|87.67171717171718|87.06397306397307 |\n",
      "|Low             |49.24912280701754|51.84561403508772|49.89122807017544|50.328654970760226|\n",
      "|Medium          |68.07736943907156|71.35976789168278|70.55319148936171|69.99677627337196 |\n",
      "+----------------+-----------------+-----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Feature means by performance level\n",
    "print(\"Average scores by Performance Level:\")\n",
    "feature_means = df.groupBy(\"PerformanceLevel\").agg(\n",
    "    *[avg(c).alias(c) for c in score_cols]\n",
    ")\n",
    "feature_means.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56f87d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Level Distribution:\n",
      "+----------------+-----+\n",
      "|PerformanceLevel|count|\n",
      "+----------------+-----+\n",
      "|            High|  198|\n",
      "|             Low|  285|\n",
      "|          Medium|  517|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performance level distribution\n",
    "print(\"Performance Level Distribution:\")\n",
    "df.groupBy(\"PerformanceLevel\").count().orderBy(\"PerformanceLevel\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b425d08",
   "metadata": {
    "id": "7b425d08"
   },
   "source": [
    "### Summary Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8af92d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8af92d5",
    "outputId": "c94c3a12-fa28-4544-92db-5d7a20ffc2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values per categorical feature:\n",
      "+------+--------------+---------------------------+-----+-----------------------+\n",
      "|gender|race/ethnicity|parental level of education|lunch|test preparation course|\n",
      "+------+--------------+---------------------------+-----+-----------------------+\n",
      "|     2|             5|                          6|    2|                      2|\n",
      "+------+--------------+---------------------------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Number of unique categories per categorical feature\n",
    "print(\"Unique values per categorical feature:\")\n",
    "categorical_summary = df.select([\n",
    "    countDistinct(c).alias(c) for c in categorical_cols\n",
    "])\n",
    "categorical_summary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KXt4nzrxr0Tr",
   "metadata": {
    "id": "KXt4nzrxr0Tr"
   },
   "source": [
    "## Phase 6: Preprocessing and ML Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d2eff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready for ML\n",
      "Shape: 1000 rows, 10 columns\n",
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: integer (nullable = true)\n",
      " |-- reading score: integer (nullable = true)\n",
      " |-- writing score: integer (nullable = true)\n",
      " |-- average_score: double (nullable = true)\n",
      " |-- PerformanceLevel: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Additional imports for ML\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Use the cleaned dataframe directly (already in memory)\n",
    "data = df_ml\n",
    "\n",
    "print(\"Dataset ready for ML\")\n",
    "print(f\"Shape: {data.count()} rows, {len(data.columns)} columns\")\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "w3FMZiOoRt_N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3FMZiOoRt_N",
    "outputId": "2e362774-2e54-4504-cda7-0e797feab6e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 838\n",
      "Test size: 162\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Train size:\", train_df.count())\n",
    "print(\"Test size:\", test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "UoCy6l_ZRzy0",
   "metadata": {
    "id": "UoCy6l_ZRzy0"
   },
   "outputs": [],
   "source": [
    "label_indexer = StringIndexer(inputCol='PerformanceLevel',outputCol='label').fit(train_df)\n",
    "\n",
    "train_df = label_indexer.transform(train_df)\n",
    "test_df = label_indexer.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "U9fgW6jsRzla",
   "metadata": {
    "id": "U9fgW6jsRzla"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical feature encoders created for: ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n"
     ]
    }
   ],
   "source": [
    "# Define categorical columns for encoding\n",
    "ml_categorical_cols = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "\n",
    "# Create indexers and encoders for categorical features\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid='keep') for c in ml_categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{c}_idx\", outputCol=f\"{c}_ohe\") for c in ml_categorical_cols]\n",
    "\n",
    "print(\"Categorical feature encoders created for:\", ml_categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7-A_bD-lSOCk",
   "metadata": {
    "id": "7-A_bD-lSOCk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric feature assembler created for: ['math score', 'reading score', 'writing score']\n"
     ]
    }
   ],
   "source": [
    "# Define numeric columns for the ML model\n",
    "# Using the three test scores as features\n",
    "ml_numeric_cols = ['math score', 'reading score', 'writing score']\n",
    "\n",
    "numeric_assembler = VectorAssembler(inputCols=ml_numeric_cols, outputCol='numeric_features')\n",
    "scaler = StandardScaler(inputCol='numeric_features', outputCol='scaled_numeric_features')\n",
    "\n",
    "print(\"Numeric feature assembler created for:\", ml_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "RkSC9r0NSNuM",
   "metadata": {
    "id": "RkSC9r0NSNuM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature assembler combines: ['scaled_numeric_features', 'gender_ohe', 'race/ethnicity_ohe', 'parental level of education_ohe', 'lunch_ohe', 'test preparation course_ohe']\n"
     ]
    }
   ],
   "source": [
    "# Combine all features into final feature vector\n",
    "feature_cols = ['scaled_numeric_features'] + [f\"{c}_ohe\" for c in ml_categorical_cols]\n",
    "\n",
    "final_assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "print(\"Final feature assembler combines:\", feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6hoXjNodShoJ",
   "metadata": {
    "id": "6hoXjNodShoJ"
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(\n",
    "featuresCol='features',\n",
    "labelCol='label'\n",
    ")\n",
    "\n",
    "rand_forest = RandomForestClassifier(\n",
    "featuresCol='features',\n",
    "labelCol='label',\n",
    "seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ZqaqH3Q3SlN9",
   "metadata": {
    "id": "ZqaqH3Q3SlN9"
   },
   "outputs": [],
   "source": [
    "lr_param_grid = (ParamGridBuilder()\n",
    ".addGrid(log_reg.regParam, [0.01, 0.1])\n",
    ".addGrid(log_reg.elasticNetParam, [0.0, 0.5])\n",
    ".build()\n",
    ")\n",
    "\n",
    "rf_param_grid = (ParamGridBuilder()\n",
    ".addGrid(rand_forest.numTrees, [50, 100])\n",
    ".addGrid(rand_forest.maxDepth, [5, 10])\n",
    ".build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "_yyBRID-SqE7",
   "metadata": {
    "id": "_yyBRID-SqE7"
   },
   "outputs": [],
   "source": [
    "common_stages = (\n",
    "indexers +\n",
    "encoders +\n",
    "[numeric_assembler,\n",
    "scaler,\n",
    "final_assembler]\n",
    ")\n",
    "\n",
    "lr_pipeline = Pipeline(stages=common_stages + [log_reg])\n",
    "rf_pipeline = Pipeline(stages=common_stages + [rand_forest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "VA3Yy1icSqdB",
   "metadata": {
    "id": "VA3Yy1icSqdB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Logistic Regression trained\n",
      "Training Random Forest...\n",
      "Random Forest trained\n",
      "\n",
      "Both models trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Simplified training without cross-validation (faster)\n",
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model = lr_pipeline.fit(train_df)\n",
    "print(\"Logistic Regression trained\")\n",
    "\n",
    "# Train Random Forest  \n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = rf_pipeline.fit(train_df)\n",
    "print(\"Random Forest trained\")\n",
    "\n",
    "print(\"\\nBoth models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "WEjDoVRMSq1x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEjDoVRMSq1x",
    "outputId": "a3114a90-2ff7-42f6-fdd8-1c462cba17bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression → Accuracy: 0.9876543209876543 F1: 0.987706208624083\n",
      "Random Forest → Accuracy: 0.9320987654320988 F1: 0.932304131422272\n"
     ]
    }
   ],
   "source": [
    "accuracy_eval = MulticlassClassificationEvaluator(\n",
    "labelCol='label',\n",
    "predictionCol='prediction',\n",
    "metricName='accuracy'\n",
    ")\n",
    "\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "labelCol='label',\n",
    "predictionCol='prediction',\n",
    "metricName='f1'\n",
    ")\n",
    "\n",
    "lr_preds = lr_model.transform(test_df)\n",
    "rf_preds = rf_model.transform(test_df)\n",
    "\n",
    "print(\"Logistic Regression →\",\n",
    "\"Accuracy:\", accuracy_eval.evaluate(lr_preds),\n",
    "\"F1:\", f1_evaluator.evaluate(lr_preds))\n",
    "\n",
    "print(\"Random Forest →\",\n",
    "\"Accuracy:\", accuracy_eval.evaluate(rf_preds),\n",
    "\"F1:\", f1_evaluator.evaluate(rf_preds))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
