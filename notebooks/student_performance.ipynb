{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa965596",
   "metadata": {},
   "source": [
    "# Student Performance Prediction (Classification)\n",
    "\n",
    "**üìä Dataset:** `student_performance.csv`  \n",
    "**üìö Source:** [Kaggle ‚Äì student_performance Dataset](https://www.kaggle.com/)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## üéØ Goal\n",
    "The goal of this project is to predict student academic performance using **supervised machine learning (classification) with Apache Spark**.  \n",
    "By analyzing students‚Äô demographic, behavioral, and academic features, the model aims to classify students based on their expected performance level, helping identify students who may need early academic support and improve educational decision-making.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## üìà Description\n",
    "The dataset includes features such as:  \n",
    "- `StudentID`, `Gender`, `AttendanceRate`, `StudyHoursPerWeek`  \n",
    "- `PreviousGrade`, `ExtracurricularActivities`, `ParentalSupport`, `OnlineClassesTaken`  \n",
    "- `FinalGrade` (Target Variable)  \n",
    "\n",
    "This project predicts students‚Äô academic performance levels to support **data-driven educational decisions**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## üìù Notebook Scope\n",
    "This notebook focuses on:  \n",
    "- Understanding the dataset  \n",
    "- Exploratory Data Analysis (EDA)  \n",
    "- Data cleaning using Apache Spark  \n",
    "- Preparing clean data for machine learning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005ce94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2516dfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark Session Created Successfully\n"
     ]
    }
   ],
   "source": [
    "# Create Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Student Performance - Data Cleaning\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark Session Created Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442eb6f",
   "metadata": {},
   "source": [
    "# Phase 1: Data Overview & Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f0661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "# Load raw dataset\n",
    "df = spark.read.csv(\n",
    "    r\"C:\\Users\\Msi\\OneDrive\\Documents\\BIg Data\\project student-performance-prediction\\data\\raw\\student_performance_updated_1000.csv\", \n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Dataset Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ef3197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Shape: 1000 rows, 12 columns\n"
     ]
    }
   ],
   "source": [
    "# Dataset Shape\n",
    "rows = df.count()\n",
    "cols = len(df.columns)\n",
    "\n",
    "print(f\"üìä Dataset Shape: {rows} rows, {cols} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8afdc256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ First 5 rows:\n",
      "+---------+-------+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "|StudentID|   Name|Gender|AttendanceRate|StudyHoursPerWeek|PreviousGrade|ExtracurricularActivities|ParentalSupport|FinalGrade|Study Hours|Attendance (%)|Online Classes Taken|\n",
      "+---------+-------+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "|      1.0|   John|  Male|          85.0|             15.0|         78.0|                      1.0|           High|      80.0|        4.8|          59.0|               false|\n",
      "|      2.0|  Sarah|Female|          90.0|             20.0|         85.0|                      2.0|         Medium|      87.0|        2.2|          70.0|                true|\n",
      "|      3.0|   Alex|  Male|          78.0|             10.0|         65.0|                      0.0|            Low|      68.0|        4.6|          92.0|               false|\n",
      "|      4.0|Michael|  Male|          92.0|             25.0|         90.0|                      3.0|           High|      92.0|        2.9|          96.0|               false|\n",
      "|      5.0|   Emma|Female|          null|             18.0|         82.0|                      2.0|         Medium|      85.0|        4.1|          97.0|                true|\n",
      "+---------+-------+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview Dataset\n",
    "print(\"üîπ First 5 rows:\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b2f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Random sample:\n",
      "+---------+--------------+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "|StudentID|          Name|Gender|AttendanceRate|StudyHoursPerWeek|PreviousGrade|ExtracurricularActivities|ParentalSupport|FinalGrade|Study Hours|Attendance (%)|Online Classes Taken|\n",
      "+---------+--------------+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "|   1949.0|Jessica Ortega|  Male|          91.0|             20.0|         null|                      1.0|           High|      72.0|        3.8|          58.0|               false|\n",
      "|   9214.0| Judith Santos|  Male|          85.0|             17.0|         85.0|                     null|            Low|      87.0|        2.5|          61.0|                true|\n",
      "|   6517.0|  Melvin Mcgee|  Male|          91.0|              8.0|         65.0|                      0.0|           High|      88.0|        4.0|          60.0|               false|\n",
      "|   6922.0|          null|  Male|          90.0|             25.0|         65.0|                      3.0|         Medium|      80.0|        1.8|          86.0|               false|\n",
      "|   1674.0|Ronald Schmidt|  Male|          90.0|             15.0|         86.0|                      2.0|            Low|      92.0|        3.8|          76.0|                true|\n",
      "+---------+--------------+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview Dataset\n",
    "print(\"üîπ Random sample:\")\n",
    "df.sample(fraction=0.01).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73946478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Dataset Schema:\n",
      "root\n",
      " |-- StudentID: double (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- AttendanceRate: double (nullable = true)\n",
      " |-- StudyHoursPerWeek: double (nullable = true)\n",
      " |-- PreviousGrade: double (nullable = true)\n",
      " |-- ExtracurricularActivities: double (nullable = true)\n",
      " |-- ParentalSupport: string (nullable = true)\n",
      " |-- FinalGrade: double (nullable = true)\n",
      " |-- Study Hours: double (nullable = true)\n",
      " |-- Attendance (%): double (nullable = true)\n",
      " |-- Online Classes Taken: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset Schema & Info\n",
    "print(\"üîπ Dataset Schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be487141",
   "metadata": {},
   "source": [
    "#### Identify Columns Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f43cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Numerical Columns: ['StudentID', 'AttendanceRate', 'StudyHoursPerWeek', 'PreviousGrade', 'ExtracurricularActivities', 'FinalGrade', 'Study Hours', 'Attendance (%)']\n"
     ]
    }
   ],
   "source": [
    "# Identify Numerical Columns pov: late night talks with your bestie \n",
    "numerical_cols = [\n",
    "    field.name for field in df.schema.fields\n",
    "    if isinstance(field.dataType, (IntegerType, DoubleType))\n",
    "]\n",
    "\n",
    "print(\"üìå Numerical Columns:\", numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f449dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Categorical Columns: ['Name', 'Gender', 'ParentalSupport', 'Online Classes Taken']\n"
     ]
    }
   ],
   "source": [
    "# Identify Categorical Columns\n",
    "categorical_cols = [\n",
    "    field.name for field in df.schema.fields\n",
    "    if field.name not in numerical_cols\n",
    "]\n",
    "print(\"üìå Categorical Columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fcc612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Unique values per column:\n",
      "StudentID: 917\n",
      "Name: 963\n",
      "Gender: 3\n",
      "AttendanceRate: 10\n",
      "StudyHoursPerWeek: 11\n",
      "PreviousGrade: 11\n",
      "ExtracurricularActivities: 5\n",
      "ParentalSupport: 4\n",
      "FinalGrade: 11\n",
      "Study Hours: 53\n",
      "Attendance (%): 53\n",
      "Online Classes Taken: 3\n"
     ]
    }
   ],
   "source": [
    "# Unique Values per Column\n",
    "print(\"üîπ Unique values per column:\")\n",
    "for col_name in df.columns:\n",
    "    print(f\"{col_name}: {df.select(col_name).distinct().count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cd296",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd378fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Missing values per column:\n",
      "+---------+----+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "|StudentID|Name|Gender|AttendanceRate|StudyHoursPerWeek|PreviousGrade|ExtracurricularActivities|ParentalSupport|FinalGrade|Study Hours|Attendance (%)|Online Classes Taken|\n",
      "+---------+----+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "|       40|  34|    48|            40|               50|           33|                       43|             22|        40|         24|            41|                  25|\n",
      "+---------+----+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Missing Values\n",
    "print(\"üîπ Missing values per column:\")\n",
    "df.select([\n",
    "    F.count(F.when(col(c).isNull(), c)).alias(c)\n",
    "    for c in df.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e28a1",
   "metadata": {},
   "source": [
    "Handle Missing Values\n",
    "Strategy:\n",
    "- Numerical ‚Üí Median (avoid skewing)\n",
    "- Categorical ‚Üí Mode (most frequent value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c50b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Numerical Missing Values (Median)\n",
    "for col_name in numerical_cols:\n",
    "    median_value = df.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "    df = df.fillna({col_name: median_value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db34e9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Column Name is empty or all null, skipping fillna.\n",
      "‚úÖ Missing values for categorical columns handled successfully\n"
     ]
    }
   ],
   "source": [
    "# Handle Categorical Missing Values (Mode)\n",
    "\n",
    "# Select categorical columns\n",
    "categorical_cols = [col for col, dtype in df.dtypes if dtype == 'string']\n",
    "\n",
    "for col_name in categorical_cols:\n",
    "    # Get the most frequent value (mode) for the column\n",
    "    mode_row = df.groupBy(col_name).count().orderBy(F.desc(\"count\")).first()\n",
    "    \n",
    "    # If mode exists and is not None, fill missing values with it\n",
    "    if mode_row is not None and mode_row[0] is not None:\n",
    "        mode_value = str(mode_row[0])  # Ensure it's a string\n",
    "        df = df.na.fill({col_name: mode_value})\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Column {col_name} is empty or all null, skipping fillna.\")\n",
    "\n",
    "print(\"‚úÖ Missing values for categorical columns handled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e35f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Missing values after cleaning:\n",
      "+---------+----+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "|StudentID|Name|Gender|AttendanceRate|StudyHoursPerWeek|PreviousGrade|ExtracurricularActivities|ParentalSupport|FinalGrade|Study Hours|Attendance (%)|Online Classes Taken|\n",
      "+---------+----+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "|        0|  34|     0|             0|                0|            0|                        0|              0|         0|          0|             0|                  25|\n",
      "+---------+----+------+--------------+-----------------+-------------+-------------------------+---------------+----------+-----------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate Missing Values Removal\n",
    "print(\"üîπ Missing values after cleaning:\")\n",
    "df.select([\n",
    "    F.count(F.when(col(c).isNull(), c)).alias(c)\n",
    "    for c in df.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b679b22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Number of duplicate rows: 0\n",
      "‚úÖ Duplicate rows removed\n",
      "üìä New Dataset Shape: 1000 rows\n"
     ]
    }
   ],
   "source": [
    "# Check Duplicates\n",
    "duplicates_count = df.count() - df.dropDuplicates().count()\n",
    "print(f\"üîπ Number of duplicate rows: {duplicates_count}\")\n",
    "\n",
    "# Remove Duplicates\n",
    "df = df.dropDuplicates()\n",
    "print(\"‚úÖ Duplicate rows removed\")\n",
    "\n",
    "print(\"üìä New Dataset Shape:\", df.count(), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9559ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Outliers handled using IQR capping\n"
     ]
    }
   ],
   "source": [
    "# Detect Outliers using IQR (Numerical Columns)\n",
    "for col_name in numerical_cols:\n",
    "    Q1 = df.approxQuantile(col_name, [0.25], 0.01)[0]\n",
    "    Q3 = df.approxQuantile(col_name, [0.75], 0.01)[0]\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    df = df.withColumn(\n",
    "        col_name,\n",
    "        when(col(col_name) < lower, lower)\n",
    "        .when(col(col_name) > upper, upper)\n",
    "        .otherwise(col(col_name))\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Outliers handled using IQR capping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c997aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Target variable (PerformanceLevel) created\n"
     ]
    }
   ],
   "source": [
    "# Create target variable for classification\n",
    "df = df.withColumn(\n",
    "    \"PerformanceLevel\",\n",
    "    when(col(\"FinalGrade\") >= 85, \"High\")\n",
    "    .when(col(\"FinalGrade\") >= 70, \"Medium\")\n",
    "    .otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Target variable (PerformanceLevel) created\")\n",
    "\n",
    "# NOTE:\n",
    "# PerformanceLevel will be used as the target variable\n",
    "# in the ML modeling phase (model.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5f9f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Final Dataset Shape:\n",
      "Rows: 1000\n",
      "Columns: 13\n",
      "üîπ Final Schema:\n",
      "root\n",
      " |-- StudentID: double (nullable = false)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Gender: string (nullable = false)\n",
      " |-- AttendanceRate: double (nullable = false)\n",
      " |-- StudyHoursPerWeek: double (nullable = false)\n",
      " |-- PreviousGrade: double (nullable = false)\n",
      " |-- ExtracurricularActivities: double (nullable = false)\n",
      " |-- ParentalSupport: string (nullable = false)\n",
      " |-- FinalGrade: double (nullable = false)\n",
      " |-- Study Hours: double (nullable = false)\n",
      " |-- Attendance (%): double (nullable = false)\n",
      " |-- Online Classes Taken: boolean (nullable = true)\n",
      " |-- PerformanceLevel: string (nullable = false)\n",
      "\n",
      "+-------+------------------+--------------+------+-----------------+-----------------+-----------------+-------------------------+---------------+-----------------+------------------+------------------+----------------+\n",
      "|summary|         StudentID|          Name|Gender|   AttendanceRate|StudyHoursPerWeek|    PreviousGrade|ExtracurricularActivities|ParentalSupport|       FinalGrade|       Study Hours|    Attendance (%)|PerformanceLevel|\n",
      "+-------+------------------+--------------+------+-----------------+-----------------+-----------------+-------------------------+---------------+-----------------+------------------+------------------+----------------+\n",
      "|  count|              1000|           966|  1000|             1000|             1000|             1000|                     1000|           1000|             1000|              1000|              1000|            1000|\n",
      "|   mean|          5412.859|          null|  null|            85.61|           17.599|           77.612|                    1.498|           null|           80.029|2.4337000000000018|            76.437|            null|\n",
      "| stddev|2600.1236459239967|          null|  null|7.200398999065666| 6.11470265741422|9.840238121421967|       1.0291040059464616|           null|9.301649298897463|1.5028199419018158|15.086007378316456|            null|\n",
      "|    min|               1.0|  Aaron Duarte|Female|             70.0|              8.0|             60.0|                      0.0|           High|             62.0|             -2.55|              50.0|            High|\n",
      "|    max|            9998.0|Zachary Daniel|  Male|             95.0|             30.0|             90.0|                      3.0|         Medium|             92.0|               5.0|             124.0|          Medium|\n",
      "+-------+------------------+--------------+------+-----------------+-----------------+-----------------+-------------------------+---------------+-----------------+------------------+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Final Cleaned Dataset Validation\n",
    "print(\"üìä Final Dataset Shape:\")\n",
    "print(\"Rows:\", df.count())\n",
    "print(\"Columns:\", len(df.columns))\n",
    "\n",
    "print(\"üîπ Final Schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220254c0",
   "metadata": {},
   "source": [
    "### Save cleaned dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e132284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset in cleaned folder\n",
    "df.toPandas().to_csv(\n",
    "    r\"C:\\Users\\Msi\\OneDrive\\Documents\\BIg Data\\project student-performance-prediction\\data\\cleaned\\student_performance_cleaned.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Cleaned dataset saved successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "student_spark_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
